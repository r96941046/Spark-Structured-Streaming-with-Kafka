{"paragraphs":[{"text":"%pyspark\nprint spark","user":"anonymous","dateUpdated":"2018-03-12T02:40:18+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"<pyspark.sql.session.SparkSession object at 0x7f8745f7d8d0>\n"}]},"apps":[],"jobName":"paragraph_1520822341881_-1695669927","id":"20180312-023901_1179934232","dateCreated":"2018-03-12T02:39:01+0000","dateStarted":"2018-03-12T02:40:18+0000","dateFinished":"2018-03-12T02:40:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3785"},{"text":"%pyspark\n# Create dataframe representing stream of output from Kafka\ndf = spark.readStream.format('kafka').option('kafka.bootstrap.servers', 'sandbox-hdp.hortonworks.com:6667').option('subscribe', 'tweets').load()\ndf","user":"anonymous","dateUpdated":"2018-03-12T02:41:42+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"DataFrame[key: binary, value: binary, topic: string, partition: int, offset: bigint, timestamp: timestamp, timestampType: int]\n"}]},"apps":[],"jobName":"paragraph_1520572749020_-1821785006","id":"20180309-051909_1897163451","dateCreated":"2018-03-09T05:19:09+0000","dateStarted":"2018-03-12T02:41:42+0000","dateFinished":"2018-03-12T02:41:47+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3786"},{"text":"%pyspark\n# Select desired columns from the dataframe\nds = df.selectExpr('CAST(key AS STRING)', 'CAST(value AS STRING)')\nds","user":"anonymous","dateUpdated":"2018-03-12T02:42:40+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"DataFrame[key: string, value: string]\n"}]},"apps":[],"jobName":"paragraph_1520576756578_-701277502","id":"20180309-062556_719306702","dateCreated":"2018-03-09T06:25:56+0000","dateStarted":"2018-03-12T02:42:41+0000","dateFinished":"2018-03-12T02:42:41+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3787"},{"text":"%pyspark\nprint ds.schema","user":"anonymous","dateUpdated":"2018-03-12T02:54:39+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"StructType(List(StructField(key,StringType,true),StructField(value,StringType,true)))\n"}]},"apps":[],"jobName":"paragraph_1520575890921_-1874218723","id":"20180309-061130_1402804576","dateCreated":"2018-03-09T06:11:30+0000","dateStarted":"2018-03-12T02:54:39+0000","dateFinished":"2018-03-12T02:54:39+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3788"},{"text":"%pyspark\n# debugging, write stream to memory\ntweetquery = ds.writeStream.queryName('tweettable').format('memory').start()\ntweetquery","user":"anonymous","dateUpdated":"2018-03-12T03:16:21+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"<pyspark.sql.streaming.StreamingQuery object at 0x7f873e4aca90>\n"}]},"apps":[],"jobName":"paragraph_1520576875181_-698235616","id":"20180309-062755_678234353","dateCreated":"2018-03-09T06:27:55+0000","dateStarted":"2018-03-12T03:16:21+0000","dateFinished":"2018-03-12T03:16:23+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3789"},{"text":"%pyspark\n# getting stream sample from table\nsample = spark.sql('select * from tweettable')\nsample.show()","user":"anonymous","dateUpdated":"2018-03-12T03:19:54+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----+--------------------+\n| key|               value|\n+----+--------------------+\n|null|{\"id\": 9730352474...|\n|null|{\"id\": 9730352265...|\n|null|{\"id\": 9730352070...|\n|null|{\"id\": 9730351212...|\n|null|{\"id\": 9730351210...|\n|null|{\"id\": 9730349730...|\n|null|{\"id\": 9730349364...|\n|null|{\"id\": 9730349045...|\n|null|{\"id\": 9730349038...|\n|null|{\"id\": 9730347298...|\n|null|{\"id\": 9730345683...|\n|null|{\"id\": 9730345462...|\n|null|{\"id\": 9730344825...|\n|null|{\"id\": 9730344248...|\n|null|{\"id\": 9730343115...|\n|null|{\"id\": 9730352474...|\n|null|{\"id\": 9730352265...|\n|null|{\"id\": 9730352070...|\n|null|{\"id\": 9730351212...|\n|null|{\"id\": 9730351210...|\n+----+--------------------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1520576364849_379914525","id":"20180309-061924_1418920442","dateCreated":"2018-03-09T06:19:24+0000","dateStarted":"2018-03-12T03:19:03+0000","dateFinished":"2018-03-12T03:19:03+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3790"},{"text":"%pyspark\nfrom pyspark.sql.functions import col, from_json\n# extract json schema from the column 'value' in sample dataframe\njson_schema = spark.read.json(sample.rdd.map(lambda row: row.value)).schema\n# to test if the schema is ok, create new column in sample dataframe\nsample = sample.withColumn('json', from_json(col('value'), json_schema))\nsample.show()","user":"anonymous","dateUpdated":"2018-03-12T03:57:42+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----+--------------------+--------------------+\n| key|               value|                json|\n+----+--------------------+--------------------+\n|null|{\"id\": 9730352474...|[Mon Mar 12 03:17...|\n|null|{\"id\": 9730352265...|[Mon Mar 12 03:17...|\n|null|{\"id\": 9730352070...|[Mon Mar 12 03:17...|\n|null|{\"id\": 9730351212...|[Mon Mar 12 03:17...|\n|null|{\"id\": 9730351210...|[Mon Mar 12 03:17...|\n|null|{\"id\": 9730349730...|[Mon Mar 12 03:16...|\n|null|{\"id\": 9730349364...|[Mon Mar 12 03:16...|\n|null|{\"id\": 9730349045...|[Mon Mar 12 03:16...|\n|null|{\"id\": 9730349038...|[Mon Mar 12 03:16...|\n|null|{\"id\": 9730347298...|[Mon Mar 12 03:15...|\n|null|{\"id\": 9730345683...|[Mon Mar 12 03:14...|\n|null|{\"id\": 9730345462...|[Mon Mar 12 03:14...|\n|null|{\"id\": 9730344825...|[Mon Mar 12 03:14...|\n|null|{\"id\": 9730344248...|[Mon Mar 12 03:14...|\n|null|{\"id\": 9730343115...|[Mon Mar 12 03:13...|\n|null|{\"id\": 9730352474...|[Mon Mar 12 03:17...|\n|null|{\"id\": 9730352265...|[Mon Mar 12 03:17...|\n|null|{\"id\": 9730352070...|[Mon Mar 12 03:17...|\n|null|{\"id\": 9730351212...|[Mon Mar 12 03:17...|\n|null|{\"id\": 9730351210...|[Mon Mar 12 03:17...|\n+----+--------------------+--------------------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1520576272332_-1516298265","id":"20180309-061752_1684505541","dateCreated":"2018-03-09T06:17:52+0000","dateStarted":"2018-03-12T03:34:04+0000","dateFinished":"2018-03-12T03:34:05+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3791"},{"text":"%pyspark\n# for testing purposes, it's also possible to run queries through the memory sink in Zeppelin to see the streaming in action\nsample.count()","user":"anonymous","dateUpdated":"2018-03-12T04:35:29+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"120\n"}]},"apps":[],"jobName":"paragraph_1520829258545_714046298","id":"20180312-043418_1854034352","dateCreated":"2018-03-12T04:34:18+0000","dateStarted":"2018-03-12T04:35:29+0000","dateFinished":"2018-03-12T04:35:30+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3792"},{"text":"%pyspark\n# streaming data can be observed\nsample.count()","user":"anonymous","dateUpdated":"2018-03-12T04:36:07+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"165\n"}]},"apps":[],"jobName":"paragraph_1520829345068_695348488","id":"20180312-043545_958489450","dateCreated":"2018-03-12T04:35:45+0000","dateStarted":"2018-03-12T04:36:07+0000","dateFinished":"2018-03-12T04:36:08+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3793"},{"text":"%pyspark\n# now that we have the json schema, let's get back to the original streaming dataframe, ds, and create the json column\nds = ds.withColumn('json', from_json(col('value'), json_schema))\nds","user":"anonymous","dateUpdated":"2018-03-12T04:03:55+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"DataFrame[key: string, value: string, json: struct<created_at:string,favorite_count:bigint,favorited:boolean,id:bigint,id_str:string,lang:string,retweet_count:bigint,retweeted:boolean,text:string>]\n"}]},"apps":[],"jobName":"paragraph_1520824635845_1761946369","id":"20180312-031715_375442829","dateCreated":"2018-03-12T03:17:15+0000","dateStarted":"2018-03-12T04:02:08+0000","dateFinished":"2018-03-12T04:02:08+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3794"},{"text":"%pyspark\n# json values can be extracted this way\nds.select(col('json.text').alias('text'))","user":"anonymous","dateUpdated":"2018-03-12T04:48:30+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-4577431814791394417.py\", line 367, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-4577431814791394417.py\", line 360, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/dataframe.py\", line 338, in show\n    print(self._jdf.showString(n, int(truncate)))\n  File \"/usr/hdp/current/spark2-client/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n    answer, self.gateway_client, self.target_id, self.name)\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/utils.py\", line 69, in deco\n    raise AnalysisException(s.split(': ', 1)[1], stackTrace)\nAnalysisException: u'Queries with streaming sources must be executed with writeStream.start();;\\nkafka'\n\n"}]},"apps":[],"jobName":"paragraph_1520576851605_-205018174","id":"20180309-062731_940988615","dateCreated":"2018-03-09T06:27:31+0000","dateStarted":"2018-03-12T04:48:09+0000","dateFinished":"2018-03-12T04:48:09+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:3795"},{"text":"%pyspark\nfrom pyspark.sql.functions import explode, split\n# Split tweet text into words\nwords = ds.select(\n    explode(\n        split(ds.json.text, ' ')\n    ).alias('word')\n)","user":"anonymous","dateUpdated":"2018-03-12T04:39:09+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1520576989486_448116892","id":"20180309-062949_1274433372","dateCreated":"2018-03-09T06:29:49+0000","dateStarted":"2018-03-12T04:39:10+0000","dateFinished":"2018-03-12T04:39:10+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3796"},{"text":"%pyspark\n# generate running word count in the result table wordCount\nwordCount = words.groupby('word').count()","user":"anonymous","dateUpdated":"2018-03-12T04:45:54+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1520829444778_1355916377","id":"20180312-043724_278815297","dateCreated":"2018-03-12T04:37:24+0000","dateStarted":"2018-03-12T04:45:54+0000","dateFinished":"2018-03-12T04:45:54+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3797"},{"text":"%pyspark\nwordCountsQuery = wordCount.writeStream.outputMode('complete').queryName('wordCounts').format('memory').start()","user":"anonymous","dateUpdated":"2018-03-12T04:45:57+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-4577431814791394417.py\", line 367, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-4577431814791394417.py\", line 360, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/streaming.py\", line 842, in start\n    return self._sq(self._jwrite.start())\n  File \"/usr/hdp/current/spark2-client/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n    answer, self.gateway_client, self.target_id, self.name)\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/utils.py\", line 79, in deco\n    raise IllegalArgumentException(s.split(': ', 1)[1], stackTrace)\nIllegalArgumentException: u'Cannot start query with name wordCounts as a query with that name is already active'\n\n"}]},"apps":[],"jobName":"paragraph_1520829444013_269770232","id":"20180312-043724_1581116162","dateCreated":"2018-03-12T04:37:24+0000","dateStarted":"2018-03-12T04:45:57+0000","dateFinished":"2018-03-12T04:45:58+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:3798"},{"text":"%pyspark\n# let's see the wordCounts result\nresult = spark.sql('select * from wordCounts')\nresult.show()","user":"anonymous","dateUpdated":"2018-03-12T04:51:36+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------+-----+\n|                word|count|\n+--------------------+-----+\n|               men.…|    2|\n|           gerektiği|    4|\n|                olup|    8|\n|                 But|    4|\n|                 방탄과|    4|\n|これはヤバすぎる！稼ぎすぎ注意報　...|    4|\n|               kelas|    4|\n|               neler|   12|\n|                tahu|    2|\n|           “instead”|    2|\n|            üzerimde|    4|\n|                  pd|    4|\n|             beating|    4|\n|https://t.co/wLL0...|    2|\n|               atas,|    4|\n|          @SuteraJo:|    6|\n|             — Franz|    4|\n|          bittiğini,|    8|\n|                 Gay|    4|\n|       gibi:Üzüntülü|    4|\n+--------------------+-----+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1520829797927_1324243253","id":"20180312-044317_1944344189","dateCreated":"2018-03-12T04:43:17+0000","dateStarted":"2018-03-12T04:51:36+0000","dateFinished":"2018-03-12T04:51:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3799"},{"text":"%pyspark\n# print the result again to show the differences\nresult.show()","user":"anonymous","dateUpdated":"2018-03-12T04:57:17+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------+-----+\n|                word|count|\n+--------------------+-----+\n|             cuidado|   21|\n|               men.…|   10|\n|           gerektiği|    4|\n|            isterdim|   24|\n|                olup|  125|\n|                 But|   10|\n|                 방탄과|    4|\n|                 ele|   11|\n|これはヤバすぎる！稼ぎすぎ注意報　...|    4|\n|               kelas|    4|\n|               neler|  131|\n|                tahu|    2|\n|           “instead”|   10|\n|            üzerimde|    4|\n|                  pd|    4|\n|         えーなにーかわいいー♡|   16|\n|             beating|   10|\n|                 ama|   24|\n|https://t.co/wLL0...|   10|\n|               atas,|    4|\n+--------------------+-----+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1520830337101_34531003","id":"20180312-045217_984971010","dateCreated":"2018-03-12T04:52:17+0000","dateStarted":"2018-03-12T04:57:17+0000","dateFinished":"2018-03-12T04:57:17+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3800"},{"text":"%pyspark\ntweetquery.stop()","user":"anonymous","dateUpdated":"2018-03-12T05:01:43+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1520577326292_-1341893166","id":"20180309-063526_1682969439","dateCreated":"2018-03-09T06:35:26+0000","dateStarted":"2018-03-12T05:01:44+0000","dateFinished":"2018-03-12T05:01:44+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3801"},{"text":"%pyspark\n","user":"anonymous","dateUpdated":"2018-03-09T06:35:54+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1520577354579_-1493252726","id":"20180309-063554_967833253","dateCreated":"2018-03-09T06:35:54+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:3802"}],"name":"Spark Structured Streaming with Kafka","id":"2DAC1XUA9","angularObjects":{"2CHS8UYQQ:shared_process":[],"2C8A4SZ9T_livy2:shared_process":[],"2CK8A9MEG:shared_process":[],"2C4U48MY3_spark2:shared_process":[],"2CKAY1A8Y:shared_process":[],"2CKEKWY8Z:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}